name: ClusterMesh with Overlapping PodCIDR (clustermesh-overlapping-podcidr-v1.13)

# Any change in triggers needs to be reflected in the concurrency group.
on:
  issue_comment:
    types:
      - created
  ### FOR TESTING PURPOSES
  # This workflow runs in the context of `master`, and ignores changes to
  # workflow files in PRs. For testing changes to this workflow from a PR:
  # - Make sure the PR uses a branch from the base repository (requires write
  #   privileges). It will not work with a branch from a fork (missing secrets).
  # - Uncomment the `pull_request` event below, commit separately with a `DO
  #   NOT MERGE` message, and push to the PR. As long as the commit is present,
  #   any push to the PR will trigger this workflow.
  # - Don't forget to remove the `DO NOT MERGE` commit once satisfied. The run
  #   will disappear from the PR checks: please provide a direct link to the
  #   successful workflow run (can be found from Actions tab) in a comment.
  #
  # pull_request: {}
  ###

# By specifying the access of one of the scopes, all of those that are not
# specified are set to 'none'.
permissions:
  # To be able to access the repository with actions/checkout
  contents: read
  # To allow retrieving information from the PR API
  pull-requests: read
  # So that Sibz/github-status-action can write into the status API
  statuses: write

concurrency:
  # Structure:
  # - Workflow name
  # - Event type
  # - A unique identifier depending on event type:
  #   - schedule: SHA
  #   - issue_comment: PR number
  #   - pull_request: PR number
  #
  # This structure ensures a unique concurrency group name is generated for each
  # type of testing:
  # - schedule: {name} schedule {SHA}
  # - issue_comment: {name} issue_comment {PR number}
  # - pull_request: {name} pull_request {PR number}
  #
  # Note: for `issue_comment` triggers, we additionally need to filter out based
  # on comment content, otherwise any comment will interrupt workflow runs.
  group: |
    ${{ github.workflow }}
    ${{ github.event_name }}
    ${{
      (github.event_name == 'schedule' && github.sha) ||
      (github.event_name == 'issue_comment' && (
        github.event.comment.body == '/clustermesh-overlapping-podcidr-v1.13' ||
        github.event.comment.body == '/test-backport-1.13'
      ) && github.event.issue.number) ||
      (github.event_name == 'pull_request' && github.event.pull_request.number)
    }}
  cancel-in-progress: true

env:
  kind_version: v0.17.0
  k8s_version: v1.24.12
  # renovate: datasource=github-releases depName=cilium/cilium-cli
  cilium_cli_version: v0.13.1
  clusterName1: cluster1-${{ github.run_id }}
  clusterName2: cluster2-${{ github.run_id }}
  contextName1: kind-cluster1-${{ github.run_id }}
  contextName2: kind-cluster2-${{ github.run_id }}
  check_url: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}

jobs:
  check_changes:
    runs-on: ubuntu-latest
    outputs:
      tested: ${{ steps.tested-tree.outputs.src }}
    steps:
      # Because we run on issue comments, we need to checkout the code for
      # paths-filter to work.
      - name: Checkout code
        if: ${{ github.event.issue.pull_request }}
        uses: actions/checkout@24cb9080177205b6e8c946b17badbe402adc938f # v3.4.0
        with:
          persist-credentials: false
      - name: Retrieve pull request's base and head
        if: ${{ github.event.issue.pull_request }}
        id: pr
        run: |
          curl ${{ github.event.issue.pull_request.url }} > pr.json
          echo "base=$(jq -r '.base.sha' pr.json)" >> $GITHUB_OUTPUT
          echo "head=$(jq -r '.head.sha' pr.json)" >> $GITHUB_OUTPUT
      - name: Check code changes
        if: ${{ github.event.issue.pull_request }}
        uses: dorny/paths-filter@4512585405083f25c027a35db413c2b3b9006d50 # v2.11.1
        id: tested-tree
        with:
          base: ${{ steps.pr.outputs.base }}
          ref: ${{ steps.pr.outputs.head }}
          filters: |
            src:
              - '!(test|Documentation)/**'

  # This job is skipped when the workflow was triggered with the generic `/test`
  # trigger if the only modified files were under `test/` or `Documentation/`.
  installation-and-connectivity:
    needs: check_changes
    name: Setup & Test
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
    - name: Checkout GitHub master
      uses: actions/checkout@24cb9080177205b6e8c946b17badbe402adc938f # v3.4.0
      with:
        ref: ${{ github.event.repository.default_branch }}
        persist-credentials: false

    - name: Set Environment Variables
      uses: ./.github/actions/set-env-variables

    - name: Set up job variables for GHA environment
      id: vars
      run: |
        if [ ${{ github.event.issue.pull_request || github.event.pull_request }} ]; then
          PR_API_JSON=$(curl \
            -H "Accept: application/vnd.github.v3+json" \
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \
            ${{ github.event.issue.pull_request.url || github.event.pull_request.url }})
          SHA=$(echo "$PR_API_JSON" | jq -r ".head.sha")
          OWNER=$(echo "$PR_API_JSON" | jq -r ".number")
        else
          SHA=${{ github.sha }}
          OWNER=${{ github.sha }}
        fi

        # bpf.masquerade is disabled due to #23283
        CILIUM_INSTALL_DEFAULTS="--chart-directory=install/kubernetes/cilium \
          --helm-set=image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/cilium-ci \
          --helm-set=image.useDigest=false \
          --helm-set=image.tag=${SHA} \
          --helm-set=operator.image.repository=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/operator \
          --helm-set=operator.image.suffix=-ci \
          --helm-set=operator.image.tag=${SHA} \
          --helm-set=operator.image.useDigest=false \
          --helm-set=bpf.masquerade=false \
          --helm-set=clustermesh.enableOverlappingPodCIDRSupport=true \
          --helm-set=socketLB.enabled=true \
          --helm-set=socketLB.hostNamespaceOnly=true \
          --helm-set=endpointHealthChecking.enabled=false \
          --helm-set=endpointStatus.enabled=true \
          --helm-set=endpointStatus.status=policy \
          --config monitor-aggregation=none \
          --rollback=false \
          --version="

        CILIUM_INSTALL_TUNNEL="--helm-set=tunnel=vxlan"

        CILIUM_INSTALL_IPFAMILY="--helm-set=ipv4.enabled=true --helm-set=ipv6.enabled=false"
        KIND_POD_CIDR_1="10.242.0.0/16"
        KIND_SVC_CIDR_1="10.243.0.0/16"
        KIND_POD_CIDR_2="10.242.0.0/16"
        KIND_SVC_CIDR_2="10.243.0.0/16"

        CLUSTERMESH_ENABLE_DEFAULTS="--apiserver-image=quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/clustermesh-apiserver-ci \
          --apiserver-version=${SHA} --service-type=NodePort"

        CONNECTIVITY_TEST_DEFAULTS="--hubble=false --flow-validation=disabled --external-target=google.com --collect-sysdump-on-failure"

        echo cilium_install_defaults="${CILIUM_INSTALL_DEFAULTS} ${CILIUM_INSTALL_TUNNEL} ${CILIUM_INSTALL_IPFAMILY}" >> $GITHUB_OUTPUT
        echo connectivity_test_defaults=${CONNECTIVITY_TEST_DEFAULTS} >> $GITHUB_OUTPUT
        echo clustermesh_enable_defaults=${CLUSTERMESH_ENABLE_DEFAULTS} >> $GITHUB_OUTPUT

        echo kind_pod_cidr_1=${KIND_POD_CIDR_1} >> $GITHUB_OUTPUT
        echo kind_svc_cidr_1=${KIND_SVC_CIDR_1} >> $GITHUB_OUTPUT
        echo kind_pod_cidr_2=${KIND_POD_CIDR_2} >> $GITHUB_OUTPUT
        echo kind_svc_cidr_2=${KIND_SVC_CIDR_2} >> $GITHUB_OUTPUT

        echo sha=${SHA} >> $GITHUB_OUTPUT

    - name: Set commit status to pending
      uses: Sibz/github-status-action@650dd1a882a76dbbbc4576fb5974b8d22f29847f # v1.1.6
      with:
        authToken: ${{ secrets.GITHUB_TOKEN }}
        sha: ${{ steps.vars.outputs.sha }}
        context: ${{ github.workflow }}
        description: Connectivity test in progress...
        state: pending
        target_url: ${{ env.check_url }}

    - name: Checkout code
      uses: actions/checkout@24cb9080177205b6e8c946b17badbe402adc938f # v3.4.0
      with:
        ref: ${{ steps.vars.outputs.sha }}
        persist-credentials: false

    - name: Install Cilium CLI
      run: |
        curl -sSL --remote-name-all https://github.com/cilium/cilium-cli/releases/download/${{ env.cilium_cli_version }}/cilium-linux-amd64.tar.gz{,.sha256sum}
        sha256sum --check cilium-linux-amd64.tar.gz.sha256sum
        sudo tar xzvfC cilium-linux-amd64.tar.gz /usr/local/bin
        rm cilium-linux-amd64.tar.gz{,.sha256sum}
        cilium version

    - name: Generate Kind configuration files
      run: |
        K8S_VERSION=${{ env.k8s_version }} \
          PODCIDR=${{ steps.vars.outputs.kind_pod_cidr_1 }} \
          SVCCIDR=${{ steps.vars.outputs.kind_svc_cidr_1 }} \
          IPFAMILY=ipv4 \
          KUBEPROXYMODE=none \
          envsubst < ./.github/kind-config.yaml.tmpl > ./.github/kind-config-cluster1.yaml

        K8S_VERSION=${{ env.k8s_version }} \
          PODCIDR=${{ steps.vars.outputs.kind_pod_cidr_2 }} \
          SVCCIDR=${{ steps.vars.outputs.kind_svc_cidr_2 }} \
          IPFAMILY=ipv4 \
          KUBEPROXYMODE=none \
          envsubst < ./.github/kind-config.yaml.tmpl > ./.github/kind-config-cluster2.yaml

    - name: Create Kind cluster 1
      uses: helm/kind-action@d8ccf8fb623ce1bb360ae2f45f323d9d5c5e9f00 # v1.5.0
      with:
        cluster_name: ${{ env.clusterName1 }}
        version: ${{ env.kind_version }}
        config: ./.github/kind-config-cluster1.yaml
        wait: 0 # The control-plane never becomes ready, since no CNI is present

    - name: Create Kind cluster 2
      uses: helm/kind-action@d8ccf8fb623ce1bb360ae2f45f323d9d5c5e9f00 # v1.5.0
      with:
        cluster_name: ${{ env.clusterName2 }}
        version: ${{ env.kind_version }}
        config: ./.github/kind-config-cluster2.yaml
        wait: 0 # The control-plane never becomes ready, since no CNI is present

    - name: Wait for images to be available
      timeout-minutes: 20
      shell: bash
      run: |
        for image in cilium-ci operator-generic-ci hubble-relay-ci clustermesh-apiserver-ci ; do
          until docker manifest inspect quay.io/${{ env.QUAY_ORGANIZATION_DEV }}/$image:${{ steps.vars.outputs.sha }} &> /dev/null; do sleep 45s; done
        done

    - name: Install Cilium in cluster1
      run: |
        # Using the deprecated flag --cluster-name due to cilium/cilium-cli#1347
        # --helm-set cluster.name ${{ env.clusterName1 }}
        cilium --context ${{ env.contextName1 }} install \
          ${{ steps.vars.outputs.cilium_install_defaults }} \
          --cluster-name ${{ env.clusterName1 }} \
          --helm-set cluster.id=1

    - name: Install Cilium in cluster2
      run: |
        # Using the deprecated form --cluster-name due to cilium/cilium-cli#1347
        # --helm-set cluster.name ${{ env.clusterName2 }}
        cilium --context ${{ env.contextName2 }} install \
          ${{ steps.vars.outputs.cilium_install_defaults }} \
          --cluster-name ${{ env.clusterName2 }} \
          --helm-set cluster.id=255 \
          --inherit-ca ${{ env.contextName1 }}

    - name: Enable Cluster Mesh
      run: |
        cilium --context ${{ env.contextName1 }} clustermesh enable ${{ steps.vars.outputs.clustermesh_enable_defaults }}
        cilium --context ${{ env.contextName2 }} clustermesh enable ${{ steps.vars.outputs.clustermesh_enable_defaults }}

    - name: Wait for cluster mesh status to be ready
      run: |
        cilium --context ${{ env.contextName1 }} status --wait
        cilium --context ${{ env.contextName2 }} status --wait
        cilium --context ${{ env.contextName1 }} clustermesh status --wait
        cilium --context ${{ env.contextName2 }} clustermesh status --wait

    - name: Connect clusters
      run: |
        cilium --context ${{ env.contextName1 }} clustermesh connect --destination-context ${{ env.contextName2 }}

    - name: Wait for cluster mesh status to be ready
      run: |
        cilium --context ${{ env.contextName1 }} status --wait
        cilium --context ${{ env.contextName2 }} status --wait
        cilium --context ${{ env.contextName1 }} clustermesh status --wait
        cilium --context ${{ env.contextName2 }} clustermesh status --wait

    - name: Deploy required resources
      run: |
        cat << EOF > netshoot.yaml
        apiVersion: v1
        kind: Pod
        metadata:
          name: netshoot
          labels:
            app: netshoot
        spec:
          nodeName: ${{ env.clusterName1 }}-worker
          containers:
          - name: netshoot
            image: nicolaka/netshoot:v0.9
            command: ["sleep", "infinite"]
        EOF
        cat << EOF > httpbin.yaml
        apiVersion: v1
        kind: Pod
        metadata:
          name: httpbin
          labels:
            app: httpbin
        spec:
          nodeName: ${{ env.clusterName2 }}-worker
          containers:
          - name: httpbin
            image: kennethreitz/httpbin
        EOF
        cat << EOF > httpbin-service.yaml
        apiVersion: v1
        kind: Service
        metadata:
          name: httpbin-service
          annotations:
            service.cilium.io/global: "true"
        spec:
          type: ClusterIP
          selector:
            app: httpbin
          ports:
            - protocol: TCP
              port: 80
              targetPort: 80
        EOF
        cat << EOF > network-policy-egress.yaml
        apiVersion: "cilium.io/v2"
        kind: CiliumNetworkPolicy
        metadata:
          name: "allow-cross-cluster-egress"
        spec:
          endpointSelector:
            matchLabels:
              app: netshoot
              io.cilium.k8s.policy.cluster: ${{ env.clusterName1 }}
          egress:
          # Allow inter-cluster communication with httpbin service
          - toEndpoints:
            - matchLabels:
                app: httpbin
                io.cilium.k8s.policy.cluster: ${{ env.clusterName2 }}
            toPorts:
            - ports:
              - port: "80"
                protocol: TCP
          # Allow name resolution
          - toEndpoints:
            - matchLabels:
                k8s-app: kube-dns
                io.kubernetes.pod.namespace: kube-system
            toPorts:
            - ports:
              - port: "53"
                protocol: ANY
        EOF
        cat << EOF > network-policy-ingress.yaml
        apiVersion: "cilium.io/v2"
        kind: CiliumNetworkPolicy
        metadata:
          name: "allow-cross-cluster-ingress"
        spec:
          endpointSelector:
            matchLabels:
              app: httpbin
              io.cilium.k8s.policy.cluster: ${{ env.clusterName2 }}
          ingress:
          - fromEndpoints:
            - matchLabels:
                app: netshoot
                io.cilium.k8s.policy.cluster: ${{ env.clusterName1 }}
        EOF

        kubectl --context ${{ env.contextName1 }} apply -f netshoot.yaml
        kubectl --context ${{ env.contextName2 }} apply -f httpbin.yaml
        kubectl --context ${{ env.contextName1 }} apply -f httpbin-service.yaml
        kubectl --context ${{ env.contextName2 }} apply -f httpbin-service.yaml
        kubectl --context ${{ env.contextName1 }} apply -f network-policy-egress.yaml
        kubectl --context ${{ env.contextName2 }} apply -f network-policy-ingress.yaml
        kubectl --context ${{ env.contextName1 }} wait pods -l app=netshoot --for condition=Ready --timeout=300s
        kubectl --context ${{ env.contextName2 }} wait pods -l app=httpbin --for condition=Ready --timeout=300s
        kubectl --context ${{ env.contextName1 }} wait --for=jsonpath='{.status.policy.egress.enforcing}'=true cep netshoot --timeout=300s
        kubectl --context ${{ env.contextName2 }} wait --for=jsonpath='{.status.policy.ingress.enforcing}'=true cep httpbin --timeout=300s

    - name: Ensure inter-cluster communication over global service with L3/L4 policy is working correctly
      run: |
        # Source address of the request should be an IP of the node that the source Pod is running on
        EXPECT=$(docker inspect ${{ env.clusterName1 }}-worker | jq -r '.[0].NetworkSettings.Networks["kind"].IPAddress')

        # Make a request to service and get origin IP address returned from server
        GOT=$(kubectl --context ${{ env.contextName1 }} exec -it netshoot -- curl -s http://httpbin-service.default.svc.cluster.local/get | jq -r .origin)

        # Check if the source address is an expected one or not. If it is expected one that means...
        # 1. Basic connectivity over global service is working
        # 2. Egress network policy was correctly applied
        # 3. Inter-cluster SNAT happened
        # 4. Ingress network policy was correctly applied even if we lose the real source IP
        if [ $GOT != $EXPECT ]; then
          echo "Connectivity test failed. Expect: ${EXPECT}, Got: ${GOT}"
          exit 1
        fi

    - name: Ensure intra-cluster communication is working as is
      run: |
        cilium --context ${{ env.contextName1 }} connectivity test ${{ steps.vars.outputs.connectivity_test_defaults }}

    - name: Post-test information gathering
      if: ${{ !success() }}
      run: |
        cilium --context ${{ env.contextName1 }} status
        cilium --context ${{ env.contextName1 }} clustermesh status
        cilium --context ${{ env.contextName2 }} status
        cilium --context ${{ env.contextName2 }} clustermesh status

        kubectl config use-context ${{ env.contextName1 }}
        kubectl get pods --all-namespaces -o wide
        cilium sysdump --output-filename cilium-sysdump-context1-final

        kubectl config use-context ${{ env.contextName2 }}
        kubectl get pods --all-namespaces -o wide
        cilium sysdump --output-filename cilium-sysdump-context2-final
      shell: bash {0} # Disable default fail-fast behaviour so that all commands run independently

    - name: Upload artifacts
      if: ${{ !success() }}
      uses: actions/upload-artifact@0b7f8abb1508181956e8e162db84b466c27e18ce # v3.1.2
      with:
        name: cilium-sysdumps
        path: cilium-sysdump-*.zip
        retention-days: 5

    - name: Set commit status to success
      if: ${{ success() }}
      uses: Sibz/github-status-action@650dd1a882a76dbbbc4576fb5974b8d22f29847f # v1.1.6
      with:
        authToken: ${{ secrets.GITHUB_TOKEN }}
        sha: ${{ steps.vars.outputs.sha }}
        context: ${{ github.workflow }}
        description: Connectivity test successful
        state: success
        target_url: ${{ env.check_url }}

    - name: Set commit status to failure
      if: ${{ failure() }}
      uses: Sibz/github-status-action@650dd1a882a76dbbbc4576fb5974b8d22f29847f # v1.1.6
      with:
        authToken: ${{ secrets.GITHUB_TOKEN }}
        sha: ${{ steps.vars.outputs.sha }}
        context: ${{ github.workflow }}
        description: Connectivity test failed
        state: failure
        target_url: ${{ env.check_url }}

    - name: Set commit status to cancelled
      if: ${{ cancelled() }}
      uses: Sibz/github-status-action@650dd1a882a76dbbbc4576fb5974b8d22f29847f # v1.1.6
      with:
        authToken: ${{ secrets.GITHUB_TOKEN }}
        sha: ${{ steps.vars.outputs.sha }}
        context: ${{ github.workflow }}
        description: Connectivity test cancelled
        state: error
        target_url: ${{ env.check_url }}
